{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](FeatEngImg/1.png \"Title\")\n",
    "![alt text](FeatEngImg/2.png \"Title\")\n",
    "\n",
    "## 聚合user id\n",
    "![alt text](FeatEngImg/3.png \"Title\")\n",
    "\n",
    "## 删除未来特征\n",
    "![alt text](FeatEngImg/4.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"concrec-rank\")\n",
    "    .config(\"spark.driver.memory\", \"11g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- episodes: string (nullable = true)\n",
      " |-- all_rating: double (nullable = true)\n",
      " |-- members: integer (nullable = true)\n",
      " |-- japanese_title: string (nullable = true)\n",
      " |-- aired: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- aired_from: integer (nullable = true)\n",
      " |-- aired_to: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "anime_df = spark.read.csv(\n",
    "    \"../anime-data/parsed_anime.csv\", header=True, inferSchema=True\n",
    ")\n",
    "anime_df = anime_df.withColumn(\"aired_from\", col(\"aired_from\").cast(\"int\"))\n",
    "\n",
    "# rename rating to all_rating\n",
    "anime_df = anime_df.withColumnRenamed(\"rating\", \"all_rating\")\n",
    "\n",
    "anime_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rating_df = spark.read.csv(\"../anime-data/rating.csv\", header=True, inferSchema=True)\n",
    "rating_df = rating_df.filter(rating_df[\"rating\"] > 0)\n",
    "rating_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_threshold = 7.5\n",
    "\n",
    "merged_df = rating_df.join(\n",
    "    anime_df.select(\n",
    "        \"anime_id\",\n",
    "        \"name\",\n",
    "        \"genre\",\n",
    "        \"type\",\n",
    "        \"episodes\",\n",
    "        \"all_rating\",\n",
    "        \"members\",\n",
    "        \"aired_from\",\n",
    "        \"aired_to\",\n",
    "    ),\n",
    "    on=[\"anime_id\"],\n",
    "    how=\"left\",\n",
    ").withColumn(\"label\", when(col(\"rating\") >= like_threshold, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Builder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. numeric features: min-max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.types as types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_PRECISION = 2\n",
    "\n",
    "\n",
    "@udf(types.FloatType())\n",
    "def extract_float(l):\n",
    "    r = __builtin__.round(l[0], NUMBER_PRECISION)\n",
    "\n",
    "    return float(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericScaler:\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.pipeline = self.__build_min_max_scalers(cols)\n",
    "\n",
    "    def __build_min_max_scalers(self, cols):\n",
    "        pipelines = [self.__build_one_min_max_scaler(col) for col in cols]\n",
    "        return Pipeline(stages=pipelines)\n",
    "\n",
    "    def __build_one_min_max_scaler(self, col):\n",
    "        output_col = f\"{col}_min_max\"\n",
    "\n",
    "        vec_assembler = VectorAssembler(\n",
    "            inputCols=[col], outputCol=f\"{col}_vec\", handleInvalid=\"keep\"\n",
    "        )\n",
    "        min_max_scaler = MinMaxScaler(inputCol=f\"{col}_vec\", outputCol=output_col)\n",
    "        pipeline = Pipeline(stages=[vec_assembler, min_max_scaler])\n",
    "\n",
    "        return pipeline\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.model = self.pipeline.fit(df)\n",
    "\n",
    "    def transform(self, df):\n",
    "        result = self.model.transform(df)\n",
    "\n",
    "        # drop all intermedia cols and convert output to float\n",
    "        for col in self.cols:\n",
    "            output_col = f\"{col}_min_max\"\n",
    "            result = result.drop(f\"{col}_vec\").withColumn(\n",
    "                output_col, extract_float(F.col(output_col))\n",
    "            )\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_numeric_cols = [\"all_rating\", \"members\", \"aired_from\", \"aired_to\"]\n",
    "\n",
    "item_numeric_scaler = NumericScaler(item_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_numeric_cols = [\n",
    "    \"user_rating_ave\",\n",
    "    \"user_rating_std\",\n",
    "    \"user_aired_from_ave\",\n",
    "    \"user_aired_to_ave\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_numeric_scaler = NumericScaler(user_numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. categorical data - multihot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "import pyspark.sql.types as types\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用已经训练好的string index mapping对genres数组进行encode\n",
    "def encode_genres_col(index_mapping_broadcasted):\n",
    "    @udf(returnType=\"array<int>\")\n",
    "    def encode_genres_col(genres, max_genre_index):\n",
    "        if genres is None:\n",
    "            genres = []\n",
    "        gen_vec = [index_mapping_broadcasted.value.get(gen) for gen in genres]\n",
    "        gen_vec = list(set(gen_vec))  # dedup\n",
    "\n",
    "        # convert genre vector to multi-hot\n",
    "        fill = np.ones(len(gen_vec), dtype=np.int32)\n",
    "        sorted_index = np.sort(gen_vec)\n",
    "        multihot_vec = SparseVector(max_genre_index + 1, sorted_index, fill)\n",
    "        return multihot_vec.toArray().astype(np.int32).tolist()\n",
    "\n",
    "    return encode_genres_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder:\n",
    "    def __init__(self, colname):\n",
    "        self.colname = colname\n",
    "\n",
    "    def fit(self, df):\n",
    "        exploded_df = df.withColumn(\"genre_item\", explode(col(\"genres\")))\n",
    "\n",
    "        genre_string_indexer = StringIndexer(\n",
    "            inputCol=\"genre_item\", outputCol=\"genre_index\"\n",
    "        )\n",
    "        indexer_model = genre_string_indexer.fit(exploded_df)\n",
    "\n",
    "        # get mapping from string indexer\n",
    "        gens_df = spark.createDataFrame(\n",
    "            [{\"genre_item\": g} for g in indexer_model.labels]\n",
    "        )\n",
    "        mapping_df = indexer_model.transform(gens_df).collect()\n",
    "        mapping_dict = {row.genre_item: int(row.genre_index) for row in mapping_df}\n",
    "        self.max_genre_index = __builtin__.max(mapping_dict.values())\n",
    "        broadcasted = spark.sparkContext.broadcast(mapping_dict)\n",
    "\n",
    "        self.encode_fn = encode_genres_col(broadcasted)\n",
    "\n",
    "    def transform(self, df):\n",
    "        return df.withColumn(\n",
    "            f\"{self.colname}_multihot\",\n",
    "            self.encode_fn(col(self.colname), lit(self.max_genre_index)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categorical_encoder = CategoricalEncoder(\"genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_categorical_encoder = CategoricalEncoder(\"user_liked_genres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset for DNN Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 帮助方法：对于某一列，在聚合的时候，如果用户不喜欢这个电影，则不聚合这个电影的信息\n",
    "likedMoviesCol = lambda colname: when(col(\"label\") == 1, col(colname)).otherwise(\n",
    "    lit(None)\n",
    ")\n",
    "\n",
    "\n",
    "@udf(returnType=\"array<string>\")\n",
    "def genre_to_list(gen_str):\n",
    "    if gen_str is None:\n",
    "        return []\n",
    "\n",
    "    gens = gen_str.split(\",\")\n",
    "    return [gen.strip() for gen in gens]\n",
    "\n",
    "\n",
    "# pick 5 most liked genres\n",
    "@udf(types.ArrayType(types.StringType()))\n",
    "def most_liked_genres(gen_strs):\n",
    "    \"\"\"\n",
    "    gen_strs = [\"Action, Adventure, Drama\", \"Comedy, Drama, School\"]\n",
    "    \"\"\"\n",
    "    gens = [s.split(\",\") for s in gen_strs]\n",
    "    gens = [x for l in gens for x in l]  # flatten\n",
    "    gens = [s.strip() for s in gens]\n",
    "\n",
    "    gen_set = set(gens)\n",
    "    count_occur = lambda gen, l: len([g for g in l if g == gen])\n",
    "    gen_with_occur = [(gen, count_occur(gen, gens)) for gen in gen_set]\n",
    "    gen_with_occur.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return [x[0] for x in gen_with_occur[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by user_id\n",
    "# sort by aired_from\n",
    "# 处理 aggregate 特征，避免引入未来信息\n",
    "\n",
    "windowSpec = Window \\\n",
    "    .partitionBy(\"user_id\") \\\n",
    "    .orderBy(\"aired_from\") \\\n",
    "      .rowsBetween(-100, -1)\n",
    "\n",
    "# 前100行，到前1行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = (\n",
    "    merged_df.withColumn(\"genres\", genre_to_list(col(\"genre\")))\n",
    "    .withColumn(\"user_rating_cnt\", count(lit(1)).over(windowSpec))\n",
    "    .withColumn(\"user_rating_ave\", mean(col(\"rating\")).over(windowSpec))\n",
    "    .withColumn(\"user_rating_ave\", F.round(col(\"user_rating_ave\"), NUMBER_PRECISION))\n",
    "    .withColumn(\"user_rating_std\", stddev(col(\"rating\")).over(windowSpec))\n",
    "    .withColumn(\"user_rating_std\", F.round(col(\"user_rating_std\"), NUMBER_PRECISION))\n",
    "    .withColumn(\n",
    "        \"user_aired_from_ave\", mean(likedMoviesCol(\"aired_from\")).over(windowSpec)\n",
    "    )\n",
    "    .withColumn(\"user_aired_from_ave\", F.round(col(\"user_aired_from_ave\"), 0))\n",
    "    .withColumn(\"user_aired_to_ave\", mean(likedMoviesCol(\"aired_to\")).over(windowSpec))\n",
    "    .withColumn(\"user_aired_to_ave\", F.round(col(\"user_aired_to_ave\"), 0))\n",
    "    .withColumn(\n",
    "        \"user_liked_genres\",\n",
    "        most_liked_genres(collect_list(likedMoviesCol(\"genre\")).over(windowSpec)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================>                            (6 + 6) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------\n",
      " anime_id            | 523                  \n",
      " user_id             | 31                   \n",
      " rating              | 7                    \n",
      " name                | Tonari no Totoro     \n",
      " genre               | Adventure, Comedy... \n",
      " type                | Movie                \n",
      " episodes            | 1                    \n",
      " all_rating          | 8.48                 \n",
      " members             | 271484               \n",
      " aired_from          | 577123200            \n",
      " aired_to            | 577123200            \n",
      " label               | 0                    \n",
      " genres              | [Adventure, Comed... \n",
      " user_rating_cnt     | 0                    \n",
      " user_rating_ave     | NULL                 \n",
      " user_rating_std     | NULL                 \n",
      " user_aired_from_ave | NULL                 \n",
      " user_aired_to_ave   | NULL                 \n",
      " user_liked_genres   | []                   \n",
      "-RECORD 1-----------------------------------\n",
      " anime_id            | 15                   \n",
      " user_id             | 31                   \n",
      " rating              | 7                    \n",
      " name                | Eyeshield 21         \n",
      " genre               | Action, Comedy, S... \n",
      " type                | TV                   \n",
      " episodes            | 145                  \n",
      " all_rating          | 8.08                 \n",
      " members             | 83648                \n",
      " aired_from          | 1112716800           \n",
      " aired_to            | 1205856000           \n",
      " label               | 0                    \n",
      " genres              | [Action, Comedy, ... \n",
      " user_rating_cnt     | 1                    \n",
      " user_rating_ave     | 7.0                  \n",
      " user_rating_std     | NULL                 \n",
      " user_aired_from_ave | NULL                 \n",
      " user_aired_to_ave   | NULL                 \n",
      " user_liked_genres   | []                   \n",
      "-RECORD 2-----------------------------------\n",
      " anime_id            | 356                  \n",
      " user_id             | 31                   \n",
      " rating              | 7                    \n",
      " name                | Fate/stay night      \n",
      " genre               | Action, Fantasy, ... \n",
      " type                | TV                   \n",
      " episodes            | 24                   \n",
      " all_rating          | 7.58                 \n",
      " members             | 374880               \n",
      " aired_from          | 1136563200           \n",
      " aired_to            | 1150473600           \n",
      " label               | 0                    \n",
      " genres              | [Action, Fantasy,... \n",
      " user_rating_cnt     | 2                    \n",
      " user_rating_ave     | 7.0                  \n",
      " user_rating_std     | 0.0                  \n",
      " user_aired_from_ave | NULL                 \n",
      " user_aired_to_ave   | NULL                 \n",
      " user_liked_genres   | []                   \n",
      "-RECORD 3-----------------------------------\n",
      " anime_id            | 1195                 \n",
      " user_id             | 31                   \n",
      " rating              | 7                    \n",
      " name                | Zero no Tsukaima     \n",
      " genre               | Action, Adventure... \n",
      " type                | TV                   \n",
      " episodes            | 13                   \n",
      " all_rating          | 7.62                 \n",
      " members             | 346828               \n",
      " aired_from          | 1151856000           \n",
      " aired_to            | 1159113600           \n",
      " label               | 0                    \n",
      " genres              | [Action, Adventur... \n",
      " user_rating_cnt     | 3                    \n",
      " user_rating_ave     | 7.0                  \n",
      " user_rating_std     | 0.0                  \n",
      " user_aired_from_ave | NULL                 \n",
      " user_aired_to_ave   | NULL                 \n",
      " user_liked_genres   | []                   \n",
      "-RECORD 4-----------------------------------\n",
      " anime_id            | 2581                 \n",
      " user_id             | 31                   \n",
      " rating              | 9                    \n",
      " name                | Mobile Suit Gunda... \n",
      " genre               | Action, Drama, Me... \n",
      " type                | TV                   \n",
      " episodes            | 25                   \n",
      " all_rating          | 8.24                 \n",
      " members             | 120351               \n",
      " aired_from          | 1191600000           \n",
      " aired_to            | 1206720000           \n",
      " label               | 1                    \n",
      " genres              | [Action, Drama, M... \n",
      " user_rating_cnt     | 4                    \n",
      " user_rating_ave     | 7.0                  \n",
      " user_rating_std     | 0.0                  \n",
      " user_aired_from_ave | NULL                 \n",
      " user_aired_to_ave   | NULL                 \n",
      " user_liked_genres   | []                   \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "feat_df.show(5, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "item_numeric_scaler.fit(feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.               (0 + 12) / 13]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jiaronghe/.pyenv/versions/3.11.3/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jiaronghe/.pyenv/versions/3.11.3/lib/python3.11/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jiaronghe/.pyenv/versions/3.11.3/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muser_numeric_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[56], line 22\u001b[0m, in \u001b[0;36mNumericScaler.fit\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pyspark/ml/pipeline.py:134\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# must be an Estimator\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     transformers\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m indexOfLastEstimator:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pyspark/ml/pipeline.py:134\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# must be an Estimator\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     transformers\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m indexOfLastEstimator:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_numeric_scaler.fit(feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "item_categorical_encoder.fit(feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_categorical_encoder.fit(feat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "## Transform data for DNN Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = item_numeric_scaler.transform(feat_df)\n",
    "transformed_df = user_numeric_scaler.transform(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 20:11:24 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 65:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " anime_id                    | 523                  \n",
      " user_id                     | 31                   \n",
      " rating                      | 7                    \n",
      " name                        | Tonari no Totoro     \n",
      " genre                       | Adventure, Comedy... \n",
      " type                        | Movie                \n",
      " episodes                    | 1                    \n",
      " all_rating                  | 8.48                 \n",
      " members                     | 271484               \n",
      " aired_from                  | 577123200            \n",
      " aired_to                    | 577123200            \n",
      " label                       | 0                    \n",
      " genres                      | [Adventure, Comed... \n",
      " user_rating_cnt             | 0                    \n",
      " user_rating_ave             | NULL                 \n",
      " user_rating_std             | NULL                 \n",
      " user_aired_from_ave         | NULL                 \n",
      " user_aired_to_ave           | NULL                 \n",
      " user_liked_genres           | []                   \n",
      " all_rating_min_max          | 0.88                 \n",
      " members_min_max             | 0.27                 \n",
      " aired_from_min_max          | 0.69                 \n",
      " aired_to_min_max            | 0.68                 \n",
      " user_rating_ave_min_max     | NaN                  \n",
      " user_rating_std_min_max     | NaN                  \n",
      " user_aired_from_ave_min_max | NaN                  \n",
      " user_aired_to_ave_min_max   | NaN                  \n",
      "-RECORD 1-------------------------------------------\n",
      " anime_id                    | 15                   \n",
      " user_id                     | 31                   \n",
      " rating                      | 7                    \n",
      " name                        | Eyeshield 21         \n",
      " genre                       | Action, Comedy, S... \n",
      " type                        | TV                   \n",
      " episodes                    | 145                  \n",
      " all_rating                  | 8.08                 \n",
      " members                     | 83648                \n",
      " aired_from                  | 1112716800           \n",
      " aired_to                    | 1205856000           \n",
      " label                       | 0                    \n",
      " genres                      | [Action, Comedy, ... \n",
      " user_rating_cnt             | 1                    \n",
      " user_rating_ave             | 7.0                  \n",
      " user_rating_std             | NULL                 \n",
      " user_aired_from_ave         | NULL                 \n",
      " user_aired_to_ave           | NULL                 \n",
      " user_liked_genres           | []                   \n",
      " all_rating_min_max          | 0.82                 \n",
      " members_min_max             | 0.08                 \n",
      " aired_from_min_max          | 0.86                 \n",
      " aired_to_min_max            | 0.87                 \n",
      " user_rating_ave_min_max     | 0.67                 \n",
      " user_rating_std_min_max     | NaN                  \n",
      " user_aired_from_ave_min_max | NaN                  \n",
      " user_aired_to_ave_min_max   | NaN                  \n",
      "-RECORD 2-------------------------------------------\n",
      " anime_id                    | 356                  \n",
      " user_id                     | 31                   \n",
      " rating                      | 7                    \n",
      " name                        | Fate/stay night      \n",
      " genre                       | Action, Fantasy, ... \n",
      " type                        | TV                   \n",
      " episodes                    | 24                   \n",
      " all_rating                  | 7.58                 \n",
      " members                     | 374880               \n",
      " aired_from                  | 1136563200           \n",
      " aired_to                    | 1150473600           \n",
      " label                       | 0                    \n",
      " genres                      | [Action, Fantasy,... \n",
      " user_rating_cnt             | 2                    \n",
      " user_rating_ave             | 7.0                  \n",
      " user_rating_std             | 0.0                  \n",
      " user_aired_from_ave         | NULL                 \n",
      " user_aired_to_ave           | NULL                 \n",
      " user_liked_genres           | []                   \n",
      " all_rating_min_max          | 0.76                 \n",
      " members_min_max             | 0.37                 \n",
      " aired_from_min_max          | 0.87                 \n",
      " aired_to_min_max            | 0.86                 \n",
      " user_rating_ave_min_max     | 0.67                 \n",
      " user_rating_std_min_max     | 0.0                  \n",
      " user_aired_from_ave_min_max | NaN                  \n",
      " user_aired_to_ave_min_max   | NaN                  \n",
      "-RECORD 3-------------------------------------------\n",
      " anime_id                    | 1195                 \n",
      " user_id                     | 31                   \n",
      " rating                      | 7                    \n",
      " name                        | Zero no Tsukaima     \n",
      " genre                       | Action, Adventure... \n",
      " type                        | TV                   \n",
      " episodes                    | 13                   \n",
      " all_rating                  | 7.62                 \n",
      " members                     | 346828               \n",
      " aired_from                  | 1151856000           \n",
      " aired_to                    | 1159113600           \n",
      " label                       | 0                    \n",
      " genres                      | [Action, Adventur... \n",
      " user_rating_cnt             | 3                    \n",
      " user_rating_ave             | 7.0                  \n",
      " user_rating_std             | 0.0                  \n",
      " user_aired_from_ave         | NULL                 \n",
      " user_aired_to_ave           | NULL                 \n",
      " user_liked_genres           | []                   \n",
      " all_rating_min_max          | 0.76                 \n",
      " members_min_max             | 0.34                 \n",
      " aired_from_min_max          | 0.87                 \n",
      " aired_to_min_max            | 0.86                 \n",
      " user_rating_ave_min_max     | 0.67                 \n",
      " user_rating_std_min_max     | 0.0                  \n",
      " user_aired_from_ave_min_max | NaN                  \n",
      " user_aired_to_ave_min_max   | NaN                  \n",
      "-RECORD 4-------------------------------------------\n",
      " anime_id                    | 2581                 \n",
      " user_id                     | 31                   \n",
      " rating                      | 9                    \n",
      " name                        | Mobile Suit Gunda... \n",
      " genre                       | Action, Drama, Me... \n",
      " type                        | TV                   \n",
      " episodes                    | 25                   \n",
      " all_rating                  | 8.24                 \n",
      " members                     | 120351               \n",
      " aired_from                  | 1191600000           \n",
      " aired_to                    | 1206720000           \n",
      " label                       | 1                    \n",
      " genres                      | [Action, Drama, M... \n",
      " user_rating_cnt             | 4                    \n",
      " user_rating_ave             | 7.0                  \n",
      " user_rating_std             | 0.0                  \n",
      " user_aired_from_ave         | NULL                 \n",
      " user_aired_to_ave           | NULL                 \n",
      " user_liked_genres           | []                   \n",
      " all_rating_min_max          | 0.85                 \n",
      " members_min_max             | 0.12                 \n",
      " aired_from_min_max          | 0.89                 \n",
      " aired_to_min_max            | 0.87                 \n",
      " user_rating_ave_min_max     | 0.67                 \n",
      " user_rating_std_min_max     | 0.0                  \n",
      " user_aired_from_ave_min_max | NaN                  \n",
      " user_aired_to_ave_min_max   | NaN                  \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transformed_df.show(5, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = item_categorical_encoder.transform(transformed_df)\n",
    "transformed_df = user_categorical_encoder.transform(transformed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data for Feature Serving\n",
    "\n",
    "1. Item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_genres_df = anime_df \\\n",
    "  .withColumn(\"genres\", genre_to_list(col(\"genre\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线上使用的 item numerical & categorical\n",
    "\n",
    "item_numeric_transformed_df = item_numeric_scaler.transform(anime_genres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_both_transformed_df = item_categorical_encoder.transform(\n",
    "    item_numeric_transformed_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. User\n",
    "\n",
    "2.1 build user feature df\n",
    "\n",
    "之前构造的feat_df已经包含每个用户最新的喜好数据了，\n",
    "只要选择feat_df中每个用户的最新数据即可，\n",
    "这里可以同样按照aired_from排序，构造window进行筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"user_id\")\n",
    "\n",
    "user_feat_df = (\n",
    "    feat_df.withColumn(\"max_aired\", max(\"aired_from\").over(w))\n",
    "    .where(col(\"aired_from\") == col(\"max_aired\"))\n",
    "    .drop(\"max_aired\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线上使用的 user numerical & categorical\n",
    "\n",
    "user_numeric_transformed_df = user_numeric_scaler.transform(user_feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_both_transformed_df = user_categorical_encoder.transform(\n",
    "    user_numeric_transformed_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Save transformed_df for DNN training\n",
    "\n",
    "2. Save Item and User features to Redis\n",
    "2.1 Collect both dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# item\n",
    "\n",
    "item_features = item_both_transformed_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(anime_id=5114, name='Fullmetal Alchemist: Brotherhood', genre='Action, Adventure, Drama, Fantasy, Magic, Military, Shounen', type='TV', episodes='64', all_rating=9.26, members=793665, japanese_title='鋼の錬金術師 FULLMETAL ALCHEMIST', aired='Apr 5, 2009 to Jul 4, 2010', image_url='https://cdn.myanimelist.net/images/anime/1223/96541.jpg', aired_from=1238860800, aired_to=1278172800, genres=['Action', 'Adventure', 'Drama', 'Fantasy', 'Magic', 'Military', 'Shounen'], all_rating_min_max=0.9900000095367432, members_min_max=0.7799999713897705, aired_from_min_max=0.8999999761581421, aired_to_min_max=0.8999999761581421, genres_multihot=[0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# user\n",
    "\n",
    "user_features = user_both_transformed_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(anime_id=16001, user_id=53, rating=9, name='Kokoro Connect: Michi Random', genre='Comedy, Drama, Romance, School, Slice of Life, Supernatural', type='Special', episodes='4', all_rating=8.19, members=106989, aired_from=1353254400, aired_to=1355068800, label=1, genres=['Comedy', 'Drama', 'Romance', 'School', 'Slice of Life', 'Supernatural'], user_rating_cnt=39, user_rating_ave=7.62, user_rating_std=1.76, user_aired_from_ave=1238832000.0, user_aired_to_ave=1247838171.0, user_liked_genres=['Romance', 'School', 'Comedy', 'Drama', 'Slice of Life'], user_rating_ave_min_max=0.7400000095367432, user_rating_std_min_max=0.2800000011920929, user_aired_from_ave_min_max=0.9300000071525574, user_aired_to_ave_min_max=0.9300000071525574, user_liked_genres_multihot=[1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Save to Redis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis import Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis = Redis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_numeric_feature_prefix = \"rank:item:num\"\n",
    "user_numeric_feature_prefix = \"rank:user:num\"\n",
    "item_categorical_feature_prefix = \"rank:item:cat\"\n",
    "user_categorical_feature_prefix = \"rank:user:cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_numeric_features(rows, features, idcol, prefix):\n",
    "    for row in rows:\n",
    "        mapping = {feat: row[feat] for feat in features}\n",
    "        key = f\"{prefix}:{row[idcol]}\"\n",
    "        redis.hset(key, mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_features = [\n",
    "    \"all_rating_min_max\",\n",
    "    \"members_min_max\",\n",
    "    \"aired_from_min_max\",\n",
    "    \"aired_to_min_max\",\n",
    "]\n",
    "\n",
    "save_numeric_features(\n",
    "    item_features,\n",
    "    item_num_features,\n",
    "    \"anime_id\",\n",
    "    item_numeric_feature_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num_features = [\n",
    "    \"user_rating_ave_min_max\",\n",
    "    \"user_rating_std_min_max\",\n",
    "    \"user_aired_from_ave_min_max\",\n",
    "    \"user_aired_to_ave_min_max\",\n",
    "]\n",
    "\n",
    "save_numeric_features(\n",
    "    user_features,\n",
    "    user_num_features,\n",
    "    \"user_id\",\n",
    "    user_numeric_feature_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def list2str(l):\n",
    "    return json.dumps(l)\n",
    "\n",
    "\n",
    "def save_categorical_features(rows, feature, idcol, prefix):\n",
    "    for row in rows:\n",
    "        mapping = {feature: list2str(row[feature])}\n",
    "        key = f\"{prefix}:{row[idcol]}\"\n",
    "        redis.hset(key, mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_categorical_features(\n",
    "    item_features,\n",
    "    \"genres_multihot\",\n",
    "    \"anime_id\",\n",
    "    item_categorical_feature_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_categorical_features(\n",
    "    user_features,\n",
    "    \"user_liked_genres_multihot\",\n",
    "    \"user_id\",\n",
    "    user_categorical_feature_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
