{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 22:48:41 WARN Utils: Your hostname, Jiarongs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.12.14 instead (on interface en0)\n",
      "24/03/31 22:48:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/03/31 22:48:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"feat-eng\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- episodes: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- members: integer (nullable = true)\n",
      " |-- japanese_title: string (nullable = true)\n",
      " |-- aired: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- aired_from: string (nullable = true)\n",
      " |-- aired_to: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anime_df = spark.read.csv('../anime-data/parsed_anime.csv', header=True, inferSchema=True)\n",
    "anime_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = anime_df \\\n",
    "    .withColumn('genre_item', explode(split(col('genre'), '[,]'))) \\\n",
    "    .withColumn('genre_item', trim(col('genre_item')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|anime_id|  genre_item|\n",
      "+--------+------------+\n",
      "|   32281|       Drama|\n",
      "|   32281|     Romance|\n",
      "|   32281|      School|\n",
      "|   32281|Supernatural|\n",
      "|    5114|      Action|\n",
      "|    5114|   Adventure|\n",
      "|    5114|       Drama|\n",
      "|    5114|     Fantasy|\n",
      "|    5114|       Magic|\n",
      "|    5114|    Military|\n",
      "+--------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_df.select(['anime_id', 'genre_item']).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_indexer = StringIndexer(inputCol='genre_item', outputCol='genre_index')\n",
    "genre_indexed_df = string_indexer \\\n",
    "    .fit(genre_df) \\\n",
    "    .transform(genre_df) \\\n",
    "    .withColumn('genre_index', col('genre_index').cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----------+\n",
      "|anime_id|  genre_item|genre_index|\n",
      "+--------+------------+-----------+\n",
      "|   32281|       Drama|          5|\n",
      "|   32281|     Romance|          8|\n",
      "|   32281|      School|          9|\n",
      "|   32281|Supernatural|         12|\n",
      "|    5114|      Action|          1|\n",
      "|    5114|   Adventure|          2|\n",
      "|    5114|       Drama|          5|\n",
      "|    5114|     Fantasy|          3|\n",
      "|    5114|       Magic|         16|\n",
      "|    5114|    Military|         23|\n",
      "+--------+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_indexed_df[['anime_id', 'genre_item', 'genre_index']].show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_multihot_df = genre_indexed_df \\\n",
    "    .groupby('anime_id') \\\n",
    "    .agg(collect_list('genre_index').alias('genre_indexes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|anime_id|       genre_indexes|\n",
      "+--------+--------------------+\n",
      "|     148|          [5, 8, 10]|\n",
      "|     463| [1, 2, 0, 3, 6, 22]|\n",
      "|     471|[0, 5, 27, 8, 9, 10]|\n",
      "|     496|    [2, 5, 3, 15, 6]|\n",
      "|     833|    [1, 0, 13, 4, 6]|\n",
      "|    1088|[1, 13, 23, 14, 8...|\n",
      "|    1238|        [2, 0, 3, 6]|\n",
      "|    1342|          [1, 5, 26]|\n",
      "|    1580|      [2, 28, 6, 12]|\n",
      "|    1591|           [0, 8, 9]|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_multihot_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_genre_index = genre_indexed_df \\\n",
    "    .agg(max(col('genre_index'))).head()['max(genre_index)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_genre_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@udf(returnType='array<int>')\n",
    "def multihot_list(l, max_index):\n",
    "    fill = np.zeros(max_index + 1, dtype=np.int32)\n",
    "    for i in l:\n",
    "        fill[i] = 1\n",
    "    return fill.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihot_df = pre_multihot_df \\\n",
    "    .withColumn(\n",
    "        'genre_multihot',\n",
    "        multihot_list(col('genre_indexes'), lit(max_genre_index))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- genre_indexes: array (nullable = false)\n",
      " |    |-- element: integer (containsNull = false)\n",
      " |-- genre_multihot: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multihot_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|anime_id|       genre_indexes|      genre_multihot|\n",
      "+--------+--------------------+--------------------+\n",
      "|     148|          [5, 8, 10]|[0, 0, 0, 0, 0, 1...|\n",
      "|     463| [1, 2, 0, 3, 6, 22]|[1, 1, 1, 1, 0, 0...|\n",
      "|     471|[0, 5, 27, 8, 9, 10]|[1, 0, 0, 0, 0, 1...|\n",
      "|     496|    [2, 5, 3, 15, 6]|[0, 0, 1, 1, 0, 1...|\n",
      "|     833|    [1, 0, 13, 4, 6]|[1, 1, 0, 0, 1, 0...|\n",
      "|    1088|[1, 13, 23, 14, 8...|[0, 1, 0, 0, 1, 0...|\n",
      "|    1238|        [2, 0, 3, 6]|[1, 0, 1, 1, 0, 0...|\n",
      "|    1342|          [1, 5, 26]|[0, 1, 0, 0, 0, 1...|\n",
      "|    1580|      [2, 28, 6, 12]|[0, 0, 1, 0, 0, 0...|\n",
      "|    1591|           [0, 8, 9]|[1, 0, 0, 0, 0, 0...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multihot_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rating_df = spark.read.csv('../anime-data/rating.csv', header=True, inferSchema=True) \\\n",
    "    .filter(col('rating') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_rating_df = rating_df \\\n",
    "    .groupby('anime_id') \\\n",
    "    .agg(mean('rating').alias('ave_rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:====>                                                   (1 + 11) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|anime_id|       ave_rating|\n",
      "+--------+-----------------+\n",
      "|   24171|7.386666666666667|\n",
      "|    9465|8.098352214212152|\n",
      "|   17679|7.293103448275862|\n",
      "|    1829|7.341757827235005|\n",
      "|    8086|7.939071817474721|\n",
      "|   17389|8.601839684625492|\n",
      "|   22097| 8.13076923076923|\n",
      "|   30654|8.687342833193629|\n",
      "|    5300|8.694010416666666|\n",
      "|    6336|8.497902097902099|\n",
      "+--------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ave_rating_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=['ave_rating'], outputCol='ave_rating_vec')\n",
    "ave_rating_scaler = MinMaxScaler(inputCol='ave_rating_vec', outputCol='ave_rating_scaled')\n",
    "pipeline = Pipeline(stages=[vec_assembler, ave_rating_scaler])\n",
    "\n",
    "rating_scaled_df = pipeline \\\n",
    "    .fit(ave_rating_df) \\\n",
    "    .transform(ave_rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- ave_rating: double (nullable = true)\n",
      " |-- ave_rating_vec: vector (nullable = true)\n",
      " |-- ave_rating_scaled: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_scaled_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-------------------+--------------------+\n",
      "|anime_id|       ave_rating|     ave_rating_vec|   ave_rating_scaled|\n",
      "+--------+-----------------+-------------------+--------------------+\n",
      "|   24171|7.386666666666667|[7.386666666666667]|[0.7096296296296296]|\n",
      "|    9465|8.098352214212152|[8.098352214212152]| [0.788705801579128]|\n",
      "|   17679|7.293103448275862|[7.293103448275862]|[0.6992337164750958]|\n",
      "|    1829|7.341757827235005|[7.341757827235005]|[0.7046397585816672]|\n",
      "|    8086|7.939071817474721|[7.939071817474721]|[0.7710079797194134]|\n",
      "|   17389|8.601839684625492|[8.601839684625492]|[0.8446488538472768]|\n",
      "|   22097| 8.13076923076923| [8.13076923076923]|[0.7923076923076922]|\n",
      "|   30654|8.687342833193629|[8.687342833193629]|[0.8541492036881809]|\n",
      "|    5300|8.694010416666666|[8.694010416666666]|[0.8548900462962962]|\n",
      "|    6336|8.497902097902099|[8.497902097902099]|[0.8331002331002332]|\n",
      "+--------+-----------------+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rating_scaled_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType='float')\n",
    "def unwrap_list(rating):\n",
    "    return rating.toArray().tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_scaled_df = rating_scaled_df \\\n",
    "    .withColumn('ave_rating_minmax', unwrap_list(col('ave_rating_scaled')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-------------------+--------------------+-----------------+\n",
      "|anime_id|       ave_rating|     ave_rating_vec|   ave_rating_scaled|ave_rating_minmax|\n",
      "+--------+-----------------+-------------------+--------------------+-----------------+\n",
      "|   24171|7.386666666666667|[7.386666666666667]|[0.7096296296296296]|       0.70962965|\n",
      "|    9465|8.098352214212152|[8.098352214212152]| [0.788705801579128]|        0.7887058|\n",
      "|   17679|7.293103448275862|[7.293103448275862]|[0.6992337164750958]|        0.6992337|\n",
      "|    1829|7.341757827235005|[7.341757827235005]|[0.7046397585816672]|       0.70463973|\n",
      "|    8086|7.939071817474721|[7.939071817474721]|[0.7710079797194134]|       0.77100796|\n",
      "|   17389|8.601839684625492|[8.601839684625492]|[0.8446488538472768]|       0.84464884|\n",
      "|   22097| 8.13076923076923| [8.13076923076923]|[0.7923076923076922]|        0.7923077|\n",
      "|   30654|8.687342833193629|[8.687342833193629]|[0.8541492036881809]|        0.8541492|\n",
      "|    5300|8.694010416666666|[8.694010416666666]|[0.8548900462962962]|       0.85489005|\n",
      "|    6336|8.497902097902099|[8.497902097902099]|[0.8331002331002332]|       0.83310026|\n",
      "+--------+-----------------+-------------------+--------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_scaled_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_result_df = rating_scaled_df \\\n",
    "    .select(['anime_id', 'ave_rating_minmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = anime_df \\\n",
    "    .join(rating_result_df, on='anime_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- episodes: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- members: integer (nullable = true)\n",
      " |-- japanese_title: string (nullable = true)\n",
      " |-- aired: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- aired_from: string (nullable = true)\n",
      " |-- aired_to: integer (nullable = true)\n",
      " |-- ave_rating_minmax: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:==============>                                          (3 + 9) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+-----+--------+------+-------+---------------------------------+--------------------+--------------------+----------+----------+-----------------+\n",
      "|anime_id|                name|               genre| type|episodes|rating|members|                   japanese_title|               aired|           image_url|aired_from|  aired_to|ave_rating_minmax|\n",
      "+--------+--------------------+--------------------+-----+--------+------+-------+---------------------------------+--------------------+--------------------+----------+----------+-----------------+\n",
      "|   24171|     Mushibugyou OVA|Action, Fantasy, ...|  OVA|       3|   7.2|   3636|          ムシブギョー 虫奉行 OVA|Jul 18, 2014 to J...|https://cdn.myani...|1405612800|1421337600|       0.70962965|\n",
      "|    9465|Break Blade 4: Sa...|Action, Fantasy, ...|Movie|       1|  7.99|  41598|ブレイク ブレイド 第四章 惨禍ノ地|        Oct 30, 2010|https://cdn.myani...|1288368000|1288368000|        0.7887058|\n",
      "|   17679|               Gambo|  Demons, Historical|Movie|       1|  6.78|   4232|                            GAMBO|        Jul 20, 2013|https://cdn.myani...|1374249600|1374249600|        0.6992337|\n",
      "|    1829|          Gedo Senki|Adventure, Fantas...|Movie|       1|  7.18|  59243|                         ゲド戦記|        Jul 29, 2006|https://cdn.myani...|1154102400|1154102400|       0.70463973|\n",
      "|    8086|Densetsu no Yuush...|Action, Adventure...|   TV|      24|  7.83| 130689|                 伝説の勇者の伝説|Jul 2, 2010 to De...|https://cdn.myani...|1278000000|1292515200|       0.77100796|\n",
      "|   17389|  Kingdom 2nd Season|Action, Historica...|   TV|      39|  8.57|  31234|           キングダム 第2シリーズ|Jun 8, 2013 to Ma...|https://cdn.myani...|1370620800|1393689600|       0.84464884|\n",
      "|   22097|Magi: Sinbad no B...|Action, Adventure...|  OVA|       5|  8.06|  52351|          マギ シンドバッドの冒険|May 14, 2014 to J...|https://cdn.myani...|1399996800|1436889600|        0.7923077|\n",
      "|   30654|Ansatsu Kyoushits...|Action, Comedy, S...|   TV|      25|  8.68| 176475|                 暗殺教室　第２期|Jan 8, 2016 to Ju...|https://cdn.myani...|1452182400|1467302400|        0.8541492|\n",
      "|    5300|Zoku Natsume Yuuj...|Drama, Fantasy, S...|   TV|      13|  8.64| 114173|                    続 夏目友人帳|Jan 6, 2009 to Ma...|https://cdn.myani...|1231171200|1238428800|       0.85489005|\n",
      "|    6336|Mobile Suit Gunda...|Action, Drama, Me...|  OVA|       7|   8.4|  42076| 機動戦士ガンダムUC（ユニコーン）|Mar 12, 2010 to J...|https://cdn.myani...|1268323200|1401984000|       0.83310026|\n",
      "+--------+--------------------+--------------------+-----+--------+------+-------+---------------------------------+--------------------+--------------------+----------+----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df \\\n",
    "    .write.format('csv') \\\n",
    "    .option('header', True) \\\n",
    "    .save('./output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
